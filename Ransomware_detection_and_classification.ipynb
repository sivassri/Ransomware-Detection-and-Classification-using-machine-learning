{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ransomware detection and classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "r2U7J0JTcHCL",
        "i8rO5XmQkGBr",
        "2wqKz5YelWV_",
        "eJWPJFQcmzGQ",
        "c8An0BWGuP0j",
        "XLgm_-XnuTfn",
        "RxZtwgNewuO3",
        "aGK1smFLxoDT",
        "epqYD18mKkeA",
        "FIy__fdf03UO",
        "77sf01RDblDy",
        "h_HfSAPQd6c7",
        "vEGcM9VSxkP6",
        "1lmbExrS8337",
        "o0VWMWZlTHQ6",
        "UXm--iUFNsMZ",
        "kp5LzVezlvC3",
        "kKR1Su8lqqS2",
        "6AkWtk16q0gL",
        "vgvMJIbevSLg",
        "-DNEi9P59cIK"
      ],
      "mount_file_id": "1mS2OyP3nKaMlkKwRXLNSAeGBEu8ttAAe",
      "authorship_tag": "ABX9TyPYXyxxXuL1mPDC1GZmzXDQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sivassri/myacc/blob/master/Ransomware_detection_and_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gWZ2R5JbunN"
      },
      "source": [
        "#Initial Setup\n",
        "\n",
        "\n",
        "1.   Change Directory\n",
        "2.   PIP Installs\n",
        "3.   Global Variables\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIENFRe76f-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01c6fefc-7291-450c-a528-b4b911a1aace"
      },
      "source": [
        "%cd /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3l_VdFpadpx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "974960fe-729c-43b1-82d4-186d47d6bcb8"
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pefile\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/1e/fc4fac0169d16a98577809400bbcfac8ad1900fa792184327b360ea51fc6/pefile-2021.5.13.tar.gz (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.4.1)\n",
            "Collecting yara-python==3.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/b7/9025babf5ac6611d741586b5cf2a9e6c264b9b80c5946ec2f6c2d103a7a5/yara-python-3.7.0.tar.gz (313kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.22.2.post1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (2.23.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.1.0)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pefile->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->-r requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 4)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 4)) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 7)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 7)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 7)) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 7)) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 4)) (1.15.0)\n",
            "Building wheels for collected packages: pefile, yara-python\n",
            "  Building wheel for pefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pefile: filename=pefile-2021.5.13-cp37-none-any.whl size=62579 sha256=c5556e0bf2bc0e3dac5b26d6e882943126bc55cd662bea60d46d5d0ae09f400f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/84/cd/c5b77cbb0c526111d3139af2455c5164a1d63e0c02142819eb\n",
            "  Building wheel for yara-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yara-python: filename=yara_python-3.7.0-cp37-cp37m-linux_x86_64.whl size=462065 sha256=d2e6f2f434299efbd797f03312ff7c714dc707805370492bcc857fa131ecdfd1\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/4e/a4/64f36edc6e9d9d9bd8e0b5d1c0bb378c48d5b71131a7c4402f\n",
            "Successfully built pefile yara-python\n",
            "Installing collected packages: pefile, yara-python, colorama\n",
            "Successfully installed colorama-0.4.4 pefile-2021.5.13 yara-python-3.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57YNEMKV6Gd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b95a544f-ee0c-4ad9-d0bf-e4263e2083d3"
      },
      "source": [
        "#PE Files paths\n",
        "%env PE_FILES = /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/dataset_pe/\n",
        "%env PE_RANSOM = /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/dataset_pe/ransomware/\n",
        "%env PE_BENIGN = /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/dataset_pe/benign/\n",
        "%env PE_LOCKER = /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/dataset_pe/Locker/\n",
        "\n",
        "#YARA Files paths\n",
        "%env YARA = /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/YARA/\n",
        "%env YARA_RULES = /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/YARA/rules/Bitcoin/\n",
        "%env YARA_COMPILED = /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/YARA/rules_compiled/Bitcoin\n",
        "\n",
        "#MLRD Paths\n",
        "%env MLRD_CSV = /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRD/dataset_csv/\n",
        "%env MLRD_LEARN = /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRD/learn/\n",
        "%env MLRD_CLASSIFIER = /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRD/classifier/\n",
        "%env MLRD_MAKE_CSV = /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRD/create_combine_csv/\n",
        "%env MLRD_DEPLOY = /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRD/MLRDdeploy/\n",
        "\n",
        "#MLRC Paths\n",
        "%env MLRC_CSV = /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRC/dataset_csv/\n",
        "%env MLRC_LEARN = /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRC/learn/\n",
        "%env MLRC_CLASSIFIER = /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRC/classifier/\n",
        "%env MLRC_MAKE_CSV = /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRC/create_combine_csv/\n",
        "%env MLRC_DEPLOY = /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRC/MLRCdeploy/\n",
        "\n",
        "# if USER is an env variable, do this\n",
        "# import os\n",
        "# user = os.environ['USER']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: PE_FILES=/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/dataset_pe/\n",
            "env: PE_RANSOM=/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/dataset_pe/ransomware/\n",
            "env: PE_BENIGN=/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/dataset_pe/benign/\n",
            "env: PE_LOCKER=/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/dataset_pe/Locker/\n",
            "env: YARA=/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/YARA/\n",
            "env: YARA_RULES=/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/YARA/rules/Bitcoin/\n",
            "env: YARA_COMPILED=/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/YARA/rules_compiled/Bitcoin\n",
            "env: MLRD_CSV=/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRD/dataset_csv/\n",
            "env: MLRD_LEARN=/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRD/learn/\n",
            "env: MLRD_CLASSIFIER=/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRD/classifier/\n",
            "env: MLRD_MAKE_CSV=/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRD/create_combine_csv/\n",
            "env: MLRD_DEPLOY=/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRD/MLRDdeploy/\n",
            "env: MLRC_CSV=/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRC/dataset_csv/\n",
            "env: MLRC_LEARN=/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRC/learn/\n",
            "env: MLRC_CLASSIFIER=/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRC/classifier/\n",
            "env: MLRC_MAKE_CSV=/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRC/create_combine_csv/\n",
            "env: MLRC_DEPLOY=/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRC/MLRCdeploy/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2U7J0JTcHCL"
      },
      "source": [
        "#MLRD\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXwCItuy6V02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8681849-264d-41ff-ec34-23ff8fd3ce76"
      },
      "source": [
        "%cd /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRD/learn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRD/learn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrEgym5Pc0Pv"
      },
      "source": [
        "\n",
        "> Create and combine Datasets(CSV files)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiHEYNx_6Yx4"
      },
      "source": [
        "!python3 create_malicious_dataset.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYRmGf15Djf7"
      },
      "source": [
        "!python3 create_benign_dataset.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh98JSCifS1d"
      },
      "source": [
        "!python3 combine_dataset.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl3q49bVc6M-"
      },
      "source": [
        "\n",
        "\n",
        "> Train and Test model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8rO5XmQkGBr"
      },
      "source": [
        "##SVM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mw_87wfK8yU",
        "outputId": "d5ed9a03-215c-4929-ac7a-2b5848d9637e"
      },
      "source": [
        "!python3 mlrd_learn_svm.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "\n",
            "[+] Training MLRD using SVM...\n",
            "\n",
            "\t[*] Training samples:  1638\n",
            "\t[*] Testing samples:  546\n",
            "\n",
            "\t[*] Cross Validation Score:  94.31 %\n",
            "\t[*] F1 Score:  95.15 %\n",
            "\t[*] Accuracy Score:  95.6 %\n",
            "\n",
            "[+] Saving algorithm and feature list in classifier directory...\n",
            "\n",
            "[-] Error: Algorithm and feature list not saved correctly.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "320lEtPZmFPb",
        "outputId": "3a97d928-1f9f-45ef-d22e-d9fa3a44c22f"
      },
      "source": [
        "!python3 mlrd_learn_svm_old.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "\n",
            "[+] Training MLRD using SVM...\n",
            "\n",
            "\t[*] Training samples:  1638\n",
            "\t[*] Testing samples:  546\n",
            "\n",
            "\t[*] Cross Validation Score:  92.3 %\n",
            "\t[*] F1 Score:  89.8 %\n",
            "\t[*] Accuracy Score:  90.78 %\n",
            "\n",
            "[+] Saving algorithm and feature list in classifier directory...\n",
            "\n",
            "[-] Error: Algorithm and feature list not saved correctly.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wqKz5YelWV_"
      },
      "source": [
        "##K-Nearest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ObHRNp9leRo",
        "outputId": "419938dd-503d-425d-ffea-4c8a319d5483"
      },
      "source": [
        "!python3 mlrd_learn_knearest.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "\n",
            "[+] Training MLRD using K-Nearest...\n",
            "\n",
            "\t[*] Training samples:  1747\n",
            "\t[*] Testing samples:  437\n",
            "\n",
            "\t[*] Cross Validation Score:  95.87 %\n",
            "\t[*] F1 Score:  95.74 %\n",
            "\t[*] Accuracy Score:  96.22 %\n",
            "\n",
            "[+] Saving algorithm and feature list in classifier directory...\n",
            "\n",
            "[*] Saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIbkN0wTmoeS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b102731-3cdd-4fd9-c98e-9c95feb8cae4"
      },
      "source": [
        "!python3 mlrd_learn_knearest_old.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "\n",
            "[+] Training MLRD using K-Nearest...\n",
            "\n",
            "\t[*] Training samples:  1747\n",
            "\t[*] Testing samples:  437\n",
            "\n",
            "\t[*] Cross Validation Score:  91.29 %\n",
            "\t[*] F1 Score:  92.32 %\n",
            "\t[*] Accuracy Score:  93.13 %\n",
            "\n",
            "[+] Saving algorithm and feature list in classifier directory...\n",
            "\n",
            "[*] Saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiWS9nRplagq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJWPJFQcmzGQ"
      },
      "source": [
        "##Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR2f_O4Om4da",
        "outputId": "142abe90-aadf-4187-b6df-5c91f9f7ef78"
      },
      "source": [
        "!python3 mlrd_learn_Ada.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "\n",
            "[+] Training MLRD using Adaboost Algorithm...\n",
            "\n",
            "\t[*] Training samples:  1747\n",
            "\t[*] Testing samples:  437\n",
            "\n",
            "\t[*] Cross Validation Score:  94.95 %\n",
            "\t[*] F1 Score:  93.63 %\n",
            "\t[*] Accuracy Score:  94.33 %\n",
            "\n",
            "[+] Saving algorithm and feature list in classifier directory...\n",
            "\n",
            "[*] Saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gC_Fl8BnRZL",
        "outputId": "b98af12d-c5e3-4ad2-ee4b-dc5aebfc4d65"
      },
      "source": [
        "!python3 mlrd_learn_Ada_old.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "\n",
            "[+] Training MLRD using Adaboost Algorithm...\n",
            "\n",
            "\t[*] Training samples:  1747\n",
            "\t[*] Testing samples:  437\n",
            "\n",
            "\t[*] Cross Validation Score:  94.03 %\n",
            "\t[*] F1 Score:  95.27 %\n",
            "\t[*] Accuracy Score:  95.76 %\n",
            "\n",
            "[+] Saving algorithm and feature list in classifier directory...\n",
            "\n",
            "[*] Saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iv2J4ssngv_"
      },
      "source": [
        "##RF(Selected)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2_EUoweni5t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d3ae3f5-50d6-4543-8e92-848407471811"
      },
      "source": [
        "!python3 mlrd_learn_RF.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "\n",
            "[+] Training MLRD using Random Forest Algorithm...\n",
            "\n",
            "\t[*] Training samples:  1747\n",
            "\t[*] Testing samples:  437\n",
            "\n",
            "\t[*] Cross Validation Score:  97.49 %\n",
            "\t[*] F1 Score:  96.46 %\n",
            "\t[*] Accuracy Score:  96.85 %\n",
            "\n",
            "[+] Saving algorithm and feature list in classifier directory...\n",
            "\n",
            "[*] Saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZzUP6h-l0FW"
      },
      "source": [
        "##Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlIU6LqKLW9F",
        "outputId": "ccdaa823-2339-4910-d3ea-f6cd20320c9a"
      },
      "source": [
        "%cd /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRD/deploy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRD/deploy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCElRGujcDB2"
      },
      "source": [
        "!python3 mlrd.py '/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/dataset_pe/Locker/VirusShare_042c8a979fc111f4fb61e820c42746db'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYLGLSq2rM6W"
      },
      "source": [
        "#MLRC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cWbQLeR6YOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cf67633-177a-4975-9603-05cbce057586"
      },
      "source": [
        "%cd /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRC/create_combine_csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/MLRC/create_combine_csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFaLD5HmrSNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b10d150a-d623-4ad9-a3ed-1e6a6a406630"
      },
      "source": [
        "!python create_locker_dataset.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"create_locker_dataset.py\", line 6, in <module>\n",
            "    import pefile\n",
            "ModuleNotFoundError: No module named 'pefile'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8An0BWGuP0j"
      },
      "source": [
        "##RF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Sc9mTmUv4wX",
        "outputId": "6053eeea-ecfb-41c8-b689-92630cd13b64"
      },
      "source": [
        "!python mlrc_learn_RF.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'mlrc_learn_RF.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztAtiRHusNSk",
        "outputId": "e812d62e-612e-45cb-e651-b38593e76086"
      },
      "source": [
        "!python mlrc_learn_RF_old.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'mlrc_learn_RF_old.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLgm_-XnuTfn"
      },
      "source": [
        "##SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHp4d_Lou-vq",
        "outputId": "d06c3263-b499-458e-9af5-b9566d9c2342"
      },
      "source": [
        "!python mlrc_learn_svm_old.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'mlrc_learn_svm_old.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxZtwgNewuO3"
      },
      "source": [
        "##adaboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycFvOQtYwxKg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58ef8baa-e0cd-4372-9057-29db862f8873"
      },
      "source": [
        "!python mlrc_learn_Ada.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'mlrc_learn_Ada.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVfePAx8xTld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bcd8490-9a03-44cf-cff8-7bbad4fa131a"
      },
      "source": [
        "!python mlrc_learn_Ada_old.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'mlrc_learn_Ada_old.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGK1smFLxoDT"
      },
      "source": [
        "##Knearest\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCSgQ4smxsL6",
        "outputId": "a3d74695-65ef-4a0b-839f-f82af865a90d"
      },
      "source": [
        "!python mlrc_learn_knearest.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'mlrc_learn_knearest.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r6Z5RsjykMA",
        "outputId": "d3fd7287-11d6-4bbb-d9ef-0c43977b388a"
      },
      "source": [
        "!python mlrc_learn_knearest_old.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'mlrc_learn_knearest_old.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epqYD18mKkeA"
      },
      "source": [
        "##MLRC Deploy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MDLgbm_KsEJ",
        "outputId": "88eadc40-05dd-4992-c1e0-abc9d7df330c"
      },
      "source": [
        "%cd /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/Full Deploy/MLRDdeploy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/Full Deploy/MLRDdeploy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oBC1HNmKns4",
        "outputId": "c3043f78-26e3-4e69-dfb0-3f643779866d"
      },
      "source": [
        "!python3 mlrd.py '/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/dataset_pe/benign/ADelRCP.exe'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"mlrd.py\", line 1, in <module>\n",
            "    import MLRCdeploy.mlrc as mlrc\n",
            "  File \"/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/Full Deploy/MLRDdeploy/MLRCdeploy/mlrc.py\", line 9, in <module>\n",
            "    import pefile\n",
            "ModuleNotFoundError: No module named 'pefile'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIy__fdf03UO"
      },
      "source": [
        "#Full Deployment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6kDmIssEtje"
      },
      "source": [
        "##Locker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CTkVFFe08WS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91248e38-1208-45e3-a58c-7defcdd50216"
      },
      "source": [
        "%cd /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/Full Deploy/MLRDdeploy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/Full Deploy/MLRDdeploy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7i5AYhV08PS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f89680e-4d9e-4cd2-c922-e9cbbfefe3d6"
      },
      "source": [
        "!python3 mlrd.py '/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/dataset_pe/Lockertest/VirusShare_8b638a770dda18903114ebe39badcd98'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "\n",
            "[+] Running Detector...\n",
            "\n",
            "\u001b[31m[*] \u001b[0mThe file VirusShare_8b638a770dda18903114ebe39badcd98 has been identified as \u001b[31mmalicious.\n",
            "\u001b[0m\n",
            "\n",
            "[+] Running Classifier...\n",
            "\n",
            "\u001b[34m[*] \u001b[0mThe file VirusShare_8b638a770dda18903114ebe39badcd98 has been identified as \u001b[34mlocker.\n",
            "\u001b[0m\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4gUSCb8Ey6n"
      },
      "source": [
        "##crypto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31AceRQ8ExJC",
        "outputId": "2a2c6942-8a2c-4246-bfce-d622b782c0c6"
      },
      "source": [
        "!python3 mlrd.py '/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/dataset_pe/cryptotest/VirusShare_0a0a3312bb6916597c63ac3cc9e52564'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "\n",
            "[+] Running Detector...\n",
            "\n",
            "\u001b[31m[*] \u001b[0mThe file VirusShare_0a0a3312bb6916597c63ac3cc9e52564 has been identified as \u001b[31mmalicious.\n",
            "\u001b[0m\n",
            "\n",
            "[+] Running Classifier...\n",
            "\n",
            "\u001b[33m[*] \u001b[0mThe file VirusShare_0a0a3312bb6916597c63ac3cc9e52564 has been identified as \u001b[33mcrypto.\n",
            "\u001b[0m\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr09dIB3E-2c"
      },
      "source": [
        "##Benign"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULvmKGSUFAr8",
        "outputId": "7658ea48-5043-405a-f78a-7d4222a6d8ff"
      },
      "source": [
        "!python3 mlrd.py '/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/dataset_pe/benigntest/7z.exe'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "\n",
            "[+] Running Detector...\n",
            "\n",
            "\u001b[32m[*] \u001b[0mThe file 7z.exe has been identified as \u001b[32mbenign.\n",
            "\u001b[0m\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77sf01RDblDy"
      },
      "source": [
        "#Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CMeM_KXDDWs"
      },
      "source": [
        "import pefile\n",
        "help(pefile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZB8a0rXTxGh"
      },
      "source": [
        "%cd /content/drive/MyDrive/proj MLRD/\n",
        "!python filecount.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl8ep8j56VLA"
      },
      "source": [
        "%cd \"path\"\n",
        "!python3 unzip.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnwEFzgHMooT"
      },
      "source": [
        "!git clone https://github.com/anujdutt9/Feature-Selection-for-Machine-Learning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_t6b_hxNTMe",
        "outputId": "ee87a6d0-e28b-4b77-da34-848ab5001a7f"
      },
      "source": [
        "%cd /content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/feature selection"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/feature selection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXgtyI2YXkKw"
      },
      "source": [
        "#Feature Selection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_HfSAPQd6c7"
      },
      "source": [
        "##Correlation method "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgLKUYpJRhIT"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n",
        "df = pd.read_csv('/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/combined_dataset.csv', nrows=2184)\n",
        "df.shape\n",
        "# df.head()\n",
        "\n",
        "# df = pd.read_csv('combined_dataset_Nofile.csv', sep=',')\n",
        "\n",
        "# Drops FileName, md5Hash and Label from data.\n",
        "numerical_features = list(df.drop(['FileName', 'md5Hash'], axis=1).columns)\n",
        "\n",
        "data = df[numerical_features]\n",
        "data.shape\n",
        "data.head()\n",
        "\n",
        "y = data['Benign']\n",
        "y.shape\n",
        "\n",
        "X = data.drop(['Benign'], axis=1)\n",
        "X.shape\n",
        "\n",
        "\n",
        "\n",
        "# Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
        "\n",
        "# # Brute Force Method to find Correlation between features\n",
        "# def correlation(data, threshold=None):\n",
        "#   # Set of all names of correlated columns\n",
        "#   col_corr = set()\n",
        "#   corr_mat = data.corr()\n",
        "#   for i in range(len(corr_mat.columns)):\n",
        "#       for j in range(i):\n",
        "#           if (abs(corr_mat.iloc[i,j]) > threshold):\n",
        "#               colname = corr_mat.columns[i]\n",
        "#               col_corr.add(colname)\n",
        "#   return col_corr\n",
        "\n",
        "# correlated_features = correlation(data=X_train, threshold=0.8)\n",
        "# print(set(correlated_features))\n",
        "\n",
        "# X_train.drop(labels=correlated_features, axis=1, inplace=True)\n",
        "# X_test.drop(labels=correlated_features, axis=1, inplace=True)\n",
        "\n",
        "# Build a Dataframe with Correlation between Features\n",
        "corr_matrix = X_train.corr()\n",
        "# Take absolute values of correlated coefficients\n",
        "corr_matrix = corr_matrix.abs().unstack()\n",
        "corr_matrix = corr_matrix.sort_values(ascending=False)\n",
        "# Take only features with correlation above threshold of 0.8\n",
        "corr_matrix = corr_matrix[corr_matrix >= 0.8]\n",
        "corr_matrix = corr_matrix[corr_matrix < 1]\n",
        "corr_matrix = pd.DataFrame(corr_matrix).reset_index()\n",
        "corr_matrix.columns = ['feature1', 'feature2', 'Correlation']\n",
        "\n",
        "# Get groups of features that are correlated amongs themselves\n",
        "grouped_features = []\n",
        "correlated_groups = []\n",
        "\n",
        "for feature in corr_matrix.feature1.unique():\n",
        "    if feature not in grouped_features:\n",
        "        # Find all features correlated to a single feature\n",
        "        correlated_block = corr_matrix[corr_matrix.feature1 == feature]\n",
        "        grouped_features = grouped_features + list(correlated_block.feature2.unique()) + [feature]\n",
        "        \n",
        "        # Append block of features to the list\n",
        "        correlated_groups.append(correlated_block)\n",
        "\n",
        "print('Found {} correlated feature groups'.format(len(correlated_groups)))\n",
        "print('out of {} total features.'.format(X_train.shape[1]))\n",
        "\n",
        "# Visualize Correlated Feature Groups\n",
        "for group in correlated_groups:\n",
        "    print(group)\n",
        "    print('\\n')\n",
        "\n",
        "# Investigating features further within one group\n",
        "group = correlated_groups[3]\n",
        "group\n",
        "# Select features with less missing data\n",
        "for features in list(group.feature2.unique()) + ['DebugSize']:\n",
        "    print(X_train[feature].isnull().sum())\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "features = list(group.feature2.unique()) + ['DebugSize']\n",
        "rfc = RandomForestClassifier(n_estimators=20, random_state=101, max_depth=4)\n",
        "rfc.fit(X_train[features].fillna(0), y_train)\n",
        "\n",
        "\n",
        "importance = pd.concat([pd.Series(features), pd.Series(rfc.feature_importances_)], axis=1)\n",
        "importance.columns = ['feature', 'importance']\n",
        "importance.sort_values(by='importance', ascending=False)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NepHIbVBpX89",
        "outputId": "3f228d45-854f-49bb-a590-532aebc80aac"
      },
      "source": [
        "\n",
        "# Import Dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Load Dataset\n",
        "# df = pd.read_csv('/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/combined_dataset.csv', nrows=2184)\n",
        "# df.head()\n",
        "\n",
        "# X = df.drop(['Benign'], axis=1)\n",
        "# X.head()\n",
        "\n",
        "\n",
        "# y = df['Benign']\n",
        "# y.head()\n",
        "\n",
        "# # Train Test Split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
        "# X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
        "\n",
        "# data_t = X_train.T\n",
        "# data_t.head()\n",
        "\n",
        "# # Search for Duplicated Columns\n",
        "# data_t.duplicated().sum()\n",
        "\n",
        "# # Visualize Duplicated Rows\n",
        "# data_t[data_t.duplicated()]\n",
        "\n",
        "# # Duplicated Features\n",
        "# duplicated_features = data_t[data_t.duplicated()].index.values\n",
        "\n",
        "# duplicated_features\n",
        "\n",
        "# #  Drop Duplicated Features\n",
        "# unique_df = data_t.drop_duplicates(keep='first').T\n",
        "# unique_df.shape\n",
        "\n",
        "# # Columns Removed from original Dataframe\n",
        "# removed_features = [col for col in df.columns if col not in unique_df.columns]\n",
        "# removed_features\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/combined_dataset.csv', nrows=2184)\n",
        "df.head()\n",
        "\n",
        "X = df.drop(['Benign'], axis=1)\n",
        "X.head()\n",
        "\n",
        "y = df['Benign']\n",
        "y.head()\n",
        "\n",
        "# Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
        "\n",
        "# check for duplicated features in the training set\n",
        "duplicated_feat = []\n",
        "for i in range(0, len(X_train.columns)):\n",
        "    # if i % 10 == 0:  # this helps me understand how the loop is going\n",
        "    #     print(i)\n",
        " \n",
        "    col_1 = X_train.columns[i]\n",
        " \n",
        "    for col_2 in X_train.columns[i + 1:]:\n",
        "        if X_train[col_1].equals(X_train[col_2]):\n",
        "            duplicated_feat.append(col_2)\n",
        "            \n",
        "len(duplicated_feat)\n",
        "\n",
        "# # Drop Duplicate Features from Training and Test Set\n",
        "# X_train.drop(labels=duplicated_feat, axis=1, inplace=True)\n",
        "# X_test.drop(labels=duplicated_feat, axis=1, inplace=True)\n",
        " \n",
        "# X_train.shape, X_test.shape\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTXhfrmtxmaY",
        "outputId": "2e327d01-8cd9-4d81-a720-b85ebf0d7441"
      },
      "source": [
        "# Exhaustive feature selection\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
        "\n",
        "\n",
        "# load dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/combined_dataset.csv', nrows=2184)\n",
        "data.shape\n",
        "\n",
        "data.head()\n",
        "\n",
        "#  Encoding categorical variables into numbers\n",
        "# numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "# numerical_vars = list(data.select_dtypes(include=numerics).columns)\n",
        "numerical_vars = list(data.columns)\n",
        "data = data[numerical_vars]\n",
        "data.shape\n",
        "\n",
        "# separate train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.drop(labels=['Benign'], axis=1),\n",
        "    data['Benign'],\n",
        "    test_size=0.3,\n",
        "    random_state=0)\n",
        "\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "# find and remove correlated features\n",
        "# in order to reduce the feature space a bit\n",
        "# so that the algorithm takes shorter\n",
        "\n",
        "def correlation(dataset, threshold):\n",
        "    col_corr = set()  # Set of all the names of correlated columns\n",
        "    corr_matrix = dataset.corr()\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
        "                colname = corr_matrix.columns[i]  # getting the name of column\n",
        "                col_corr.add(colname)\n",
        "    return col_corr\n",
        "\n",
        "corr_features = correlation(X_train, 0.8)\n",
        "print('correlated features: ', set(corr_features) )\n",
        "\n",
        "\n",
        "# removed correlated  features\n",
        "X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
        "X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
        "\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "X_train.columns[0:10]\n",
        "\n",
        "\n",
        "# exhaustive feature selection\n",
        "# Using 10 features with ROC_AUC Scoring\n",
        "\n",
        "# n_jobs : int (default: 1)\n",
        "#     The number of CPUs to use for evaluating different feature subsets\n",
        "efs1 = EFS(RandomForestClassifier(n_jobs=4, random_state=0), \n",
        "           min_features=1,\n",
        "           max_features=4, \n",
        "           scoring='roc_auc',\n",
        "           print_progress=True,\n",
        "           cv=2)\n",
        "\n",
        "efs1 = efs1.fit(np.array(X_train[X_train.columns[0:4]].fillna(0)), y_train)\n",
        "\n",
        "def run_randomForests(X_train, X_test, y_train, y_test):\n",
        "    rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
        "    rf.fit(X_train, y_train)\n",
        "    print('Train set')\n",
        "    pred = rf.predict_proba(X_train)\n",
        "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
        "    print('Test set')\n",
        "    pred = rf.predict_proba(X_test)\n",
        "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
        "\n",
        "efs1.best_idx_\n",
        "\n",
        "selected_feat= X_train.columns[list(efs1.best_idx_)]\n",
        "print(selected_feat)\n",
        "\n",
        "  # efs1 = EFS(RandomForestClassifier(n_jobs=4, random_state=0), \n",
        "  #           min_features=1,\n",
        "  #           max_features=4, \n",
        "  #           scoring='roc_auc',\n",
        "  #           print_progress=True,\n",
        "  #           cv=2)\n",
        "\n",
        "  # efs1 = efs1.fit(np.array(X_train[X_train.columns[0:4]].fillna(0)), y_train)\n",
        "\n",
        "  # def run_randomForests(X_train, X_test, y_train, y_test):\n",
        "  #     rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
        "  #     rf.fit(X_train, y_train)\n",
        "  #     print('Train set')\n",
        "  #     pred = rf.predict_proba(X_train)\n",
        "  #     print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
        "  #     print('Test set')\n",
        "  #     pred = rf.predict_proba(X_test)\n",
        "  #     print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
        "\n",
        "  # efs1.best_idx_\n",
        "\n",
        "  # selected_feat= X_train.columns[list(efs1.best_idx_)]\n",
        "  # print(selected_feat)\n",
        "\n",
        "\n",
        "# evaluate performance of classifier using selected features\n",
        "\n",
        "run_randomForests(X_train[selected_feat].fillna(0),\n",
        "                  X_test[selected_feat].fillna(0),\n",
        "                  y_train, y_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correlated features:  set()\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Features: 15/15"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Index(['MajorOSVersion', 'ExportRVA', 'IatVRA'], dtype='object')\n",
            "Train set\n",
            "Random Forests roc-auc: 0.7743794326241135\n",
            "Test set\n",
            "Random Forests roc-auc: 0.6915634674922602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWja6J015_Om",
        "outputId": "29d0571c-5440-41ae-9df7-7a54c45151e6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "\n",
        "# load dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/proj MLRD/MLRD-Machine-Learning-Ransomware-Detection/combined_dataset.csv', nrows=2184)\n",
        "data.shape\n",
        "\n",
        "data.head()\n",
        "\n",
        "#  Encoding categorical variables into numbers\n",
        "# numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "# numerical_vars = list(data.select_dtypes(include=numerics).columns)\n",
        "numerical_vars = list(df.drop(['FileName', 'md5Hash'], axis=1).columns)\n",
        "data = data[numerical_vars]\n",
        "data.shape\n",
        "\n",
        "# separate train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.drop(labels=['Benign'], axis=1),\n",
        "    data['Benign'],\n",
        "    test_size=0.3,\n",
        "    random_state=0)\n",
        "\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "\n",
        "\n",
        "# find and remove correlated features\n",
        "# in order to reduce the feature space a bit\n",
        "# so that the algorithm takes shorter to find\n",
        "# the features\n",
        "\n",
        "def correlation(dataset, threshold):\n",
        "    col_corr = set()  # Set of all the names of correlated columns\n",
        "    corr_matrix = dataset.corr()\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
        "                colname = corr_matrix.columns[i]  # getting the name of column\n",
        "                col_corr.add(colname)\n",
        "    return col_corr\n",
        "\n",
        "corr_features = correlation(X_train, 0.8)\n",
        "print('correlated features: ', set(corr_features) )\n",
        "\n",
        "# removed correlated  features\n",
        "X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
        "X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
        "\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "\n",
        "# step backward feature selection\n",
        "# Using 15 features with ROC_AUC scoring\n",
        "\n",
        "sfs1 = SFS(RandomForestClassifier(n_jobs=4), \n",
        "           k_features=15, \n",
        "           forward=False, \n",
        "           floating=False, \n",
        "           verbose=2,\n",
        "           scoring='roc_auc',\n",
        "           cv=3)\n",
        "\n",
        "sfs1 = sfs1.fit(np.array(X_train.fillna(0)), y_train)\n",
        "\n",
        "def run_randomForests(X_train, X_test, y_train, y_test):\n",
        "    rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
        "    rf.fit(X_train, y_train)\n",
        "    print('Train set')\n",
        "    pred = rf.predict_proba(X_train)\n",
        "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
        "    print('Test set')\n",
        "    pred = rf.predict_proba(X_test)\n",
        "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))\n",
        "\n",
        "\n",
        "selected_feat= X_train.columns[list(sfs1.k_feature_idx_)]\n",
        "selected_feat\n",
        "\n",
        "\n",
        "# evaluate performance of algorithm built\n",
        "# using selected features\n",
        "\n",
        "run_randomForests(X_train[selected_feat].fillna(0),\n",
        "                  X_test[selected_feat].fillna(0),\n",
        "                  y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correlated features:  {'Magic', 'ExportSize'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n",
            "\n",
            "STOPPING EARLY DUE TO KEYBOARD INTERRUPT..."
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set\n",
            "Random Forests roc-auc: 0.984075246787111\n",
            "Test set\n",
            "Random Forests roc-auc: 0.9924251075330212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "864RFmStMcMu"
      },
      "source": [
        ""
      ]
    }
  ]
}